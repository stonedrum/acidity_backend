import os
# å¿…é¡»åœ¨å¯¼å…¥ä»»ä½• huggingface ç›¸å…³åº“ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['HF_DATASETS_OFFLINE'] = '1'

from fastapi import FastAPI, Depends, UploadFile, File, HTTPException, status, Form
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc
from .database import get_db, init_db
from .models import User, Document, Clause, ApiCallLog, ChatQueryLog, Prompt, DictType, DictData
from .schemas import (
    UserCreate, UserLogin, Token, DocumentOut, SearchQuery, ClauseOut, 
    ChatRequest, ChatQueryLogOut, PaginatedChatLogs, LogQueryParams, 
    PromptOut, PromptCreate, PromptUpdate, DictDataOut, DictTypeOut,
    DictTypeCreate, DictTypeUpdate, DictDataCreate, DictDataUpdate,
    ClauseCreate, ClauseUpdate, PaginatedClauses
)
from .auth import get_password_hash, verify_password, create_access_token, get_current_user
from .services.oss_service import oss_service
from .services.pdf_service import pdf_service
from .services.rag_service import rag_service
from .services.llm_service import llm_service
from .config import settings
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response
import shutil
import uuid
from uuid import UUID
import time
import json
from datetime import datetime
from typing import Optional, List

app = FastAPI(title="Standard Knowledge Base RAG")

@app.on_event("startup")
async def startup_event():
    await init_db()
    # åˆå§‹åŒ–é»˜è®¤æç¤ºè¯
    from .database import AsyncSessionLocal
    async with AsyncSessionLocal() as db:
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ rag_system_prompt
        stmt = select(Prompt).where(Prompt.name == "rag_system_prompt")
        result = await db.execute(stmt)
        if not result.scalar_one_or_none():
            default_prompt = """ä½ æ˜¯å¸‚æ”¿è®¾æ–½è¿ç»´ä¸“å®¶ï¼Œç²¾é€šç»“æ„å¥åº·ç›‘æµ‹ã€ç—…å®³è¯Šæ–­ã€å…»æŠ¤ä¿®å¤ã€åº”æ€¥å¤„ç½®åŠè¡Œä¸šè§„èŒƒã€‚è¯·åŸºäºå¸‚æ”¿è®¾æ–½å…¨ç”Ÿå‘½å‘¨æœŸè¿ç»´ç»éªŒï¼Œç”¨ä¸“ä¸šã€ç®€æ´çš„è¯­è¨€è§£ç­”é“æ¡¥éš§å·¡æ£€ã€ç»´ä¿®ã€ç®¡ç†ç›¸å…³é—®é¢˜ã€‚
å°†æ ¹æ®æä¾›çš„ã€å‚è€ƒèµ„æ–™ã€‘æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ã€‚
ä½ çš„å›ç­”åº”ä½“ç°å¸‚æ”¿è®¾æ–½è¿ç»´ä¸“å®¶çš„èº«ä»½ï¼šé€»è¾‘æ¸…æ™°ã€æœ¯è¯­è§„èŒƒã€å¼ºè°ƒå®‰å…¨ä¸åˆè§„ã€‚

é‡è¦æç¤ºï¼šè¯·ä¸è¦åœ¨å›ç­”ä¸­åŒ…å«å¼•ç”¨æ–‡ä»¶ã€å‚è€ƒæ–‡çŒ®æˆ–é“¾æ¥ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å°†ç”±ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{context}
"""
            new_prompt = Prompt(
                name="rag_system_prompt",
                template=default_prompt,
                description="RAG ç³»ç»Ÿçš„æ ¸å¿ƒæç¤ºè¯æ¨¡æ¿"
            )
            db.add(new_prompt)
            await db.commit()
            print("[INFO] å·²åˆå§‹åŒ–é»˜è®¤æç¤ºè¯ï¼šrag_system_prompt")
        
        # --- åˆå§‹åŒ–çŸ¥è¯†åº“ç±»å‹å­—å…¸ ---
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ kb_type å­—å…¸ç±»å‹
        stmt = select(DictType).where(DictType.type_name == "kb_type")
        result = await db.execute(stmt)
        kb_type_dict = result.scalar_one_or_none()
        
        if not kb_type_dict:
            # åˆ›å»ºå­—å…¸ç±»å‹
            kb_type_dict = DictType(type_name="kb_type", description="çŸ¥è¯†åº“æ‰€å±ç±»å‹åˆ†ç±»")
            db.add(kb_type_dict)
            await db.flush() # è·å– ID
            
            # åˆ›å»ºåˆå§‹å­—å…¸æ•°æ®
            default_data = [
                {"label": "æ¡¥æ¢", "value": "bridge", "sort": 1},
                {"label": "é“è·¯", "value": "road", "sort": 2},
                {"label": "éš§é“", "value": "tunnel", "sort": 3},
                {"label": "å…¬å›­ç»¿åŒ–", "value": "park", "sort": 4},
                {"label": "æ’æ°´", "value": "drainage", "sort": 5}
            ]
            for item in default_data:
                db.add(DictData(
                    type_id=kb_type_dict.id,
                    label=item["label"],
                    value=item["value"],
                    sort_order=item["sort"]
                ))
            await db.commit()
            print("[INFO] å·²åˆå§‹åŒ–æ•°æ®å­—å…¸ï¼škb_type")

async def get_prompt(db: AsyncSession, name: str, default_template: str = None) -> str:
    """ä»æ•°æ®åº“è·å–æç¤ºè¯"""
    stmt = select(Prompt).where(Prompt.name == name, Prompt.is_active == True)
    result = await db.execute(stmt)
    prompt_obj = result.scalar_one_or_none()
    return prompt_obj.template if prompt_obj else default_template

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ¥å£è°ƒç”¨æ—¥å¿—ä¸­é—´ä»¶
class ApiLoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        
        # è·å–ç”¨æˆ·åï¼ˆä»tokenä¸­è§£æï¼Œå¦‚æœå­˜åœ¨ï¼‰
        username = None
        try:
            auth_header = request.headers.get("Authorization")
            if auth_header and auth_header.startswith("Bearer "):
                token = auth_header.split(" ")[1]
                from jose import jwt
                try:
                    payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
                    username = payload.get("sub")
                except:
                    pass
        except:
            pass
        
        # è·å–è¯·æ±‚å‚æ•°
        body = None
        try:
            if request.method in ["POST", "PUT", "PATCH"]:
                body_bytes = await request.body()
                if body_bytes:
                    try:
                        body = json.loads(body_bytes.decode())
                    except:
                        body = {"raw": body_bytes.decode()[:500]}  # é™åˆ¶é•¿åº¦
        except:
            pass
        
        # æ‰§è¡Œè¯·æ±‚
        response = await call_next(request)
        
        # è®¡ç®—å“åº”æ—¶é—´
        response_time_ms = (time.time() - start_time) * 1000
        
        # è®°å½•æ—¥å¿—ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å“åº”ï¼‰
        # æ³¨æ„ï¼šä¸­é—´ä»¶ä¸­ç›´æ¥è®¿é—®æ•°æ®åº“æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        # å®é™…è®°å½•åœ¨æ¥å£å±‚é¢å®Œæˆï¼Œä¸­é—´ä»¶ä¸»è¦ç”¨äºç»Ÿè®¡
        pass
        
        return response

app.add_middleware(ApiLoggingMiddleware)

@app.on_event("startup")
async def startup():
    await init_db()

@app.post("/register", response_model=Token)
async def register(user_data: UserCreate, db: AsyncSession = Depends(get_db)):
    db_user = await db.execute(select(User).where(User.username == user_data.username))
    if db_user.scalar_one_or_none():
        raise HTTPException(status_code=400, detail="Username already registered")
    
    hashed_password = get_password_hash(user_data.password)
    new_user = User(username=user_data.username, password_hash=hashed_password)
    db.add(new_user)
    await db.commit()
    
    access_token = create_access_token(data={"sub": new_user.username})
    return {"access_token": access_token, "token_type": "bearer"}

@app.post("/token", response_model=Token)
async def login(user_data: UserLogin, db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(User).where(User.username == user_data.username))
    user = result.scalar_one_or_none()
    if not user or not verify_password(user_data.password, user.password_hash):
        raise HTTPException(status_code=401, detail="Incorrect username or password")
    
    access_token = create_access_token(data={"sub": user.username})
    return {"access_token": access_token, "token_type": "bearer"}

@app.post("/upload")
async def upload_pdf(
    file: UploadFile = File(...), 
    kb_type: str = Form(...),  # æ¥æ”¶çŸ¥è¯†åº“ç±»å‹
    db: AsyncSession = Depends(get_db), 
    current_user: str = Depends(get_current_user)
):
    # 1. Save locally temporarily
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)
    temp_file_path = os.path.join(temp_dir, f"{uuid.uuid4()}_{file.filename}")
    with open(temp_file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    try:
        # 2. Generate UUID-based filename (remove hyphens and keep file extension)
        # ç”ŸæˆåŸºäºUUIDçš„æ–‡ä»¶åï¼ˆå»æ‰æ¨ªçº¿ï¼Œä¿ç•™æ–‡ä»¶æ‰©å±•åï¼‰
        file_ext = os.path.splitext(file.filename)[1]  # è·å–æ–‡ä»¶æ‰©å±•åï¼Œå¦‚ .pdf
        uuid_name = str(uuid.uuid4()).replace('-', '')  # ç”ŸæˆUUIDå¹¶å»æ‰æ¨ªçº¿
        oss_filename = f"{uuid_name}{file_ext}"  # ç»„åˆï¼šuuidæ–‡ä»¶å + æ‰©å±•å
        
        # 3. Upload to OSS (ä¸Šä¼ åˆ° /laws/ ç›®å½•ï¼Œä½¿ç”¨UUIDæ–‡ä»¶å)
        with open(temp_file_path, "rb") as f:
            oss_key = oss_service.upload_file(f.read(), oss_filename, directory="laws")
        
        # 4. Check if filename already exists (filename must be unique)
        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨ï¼ˆæ–‡ä»¶åå¿…é¡»å”¯ä¸€ï¼‰
        existing_doc = await db.execute(select(Document).where(Document.filename == file.filename))
        if existing_doc.scalar_one_or_none():
            raise HTTPException(
                status_code=400, 
                detail=f"æ–‡ä»¶ '{file.filename}' å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å"
            )
        
        # 5. Create Document record (ä¿å­˜åŸå§‹æ–‡ä»¶åï¼ŒOSS keyä½¿ç”¨UUIDæ–‡ä»¶åï¼Œè®°å½•ä¸Šä¼ äººï¼Œè®°å½•çŸ¥è¯†åº“ç±»å‹)
        doc = Document(
            filename=file.filename, 
            oss_key=oss_key,
            uploader=current_user,  # è®°å½•ä¸Šä¼ ç”¨æˆ·å
            kb_type=kb_type        # è®°å½•çŸ¥è¯†åº“ç±»å‹
        )
        db.add(doc)
        await db.flush() # Get doc.id
        
        # 6. Parse PDF
        clauses_data = pdf_service.parse_pdf(temp_file_path)
        
        # 7. Embedding and Save Clauses
        for item in clauses_data:
            embedding = rag_service.get_embedding(item["content"])
            clause = Clause(
                doc_id=doc.id,
                kb_type=kb_type, # å†—ä½™å­˜å‚¨ç±»å‹
                chapter_path=item["chapter_path"],
                content=item["content"],
                embedding=embedding
            )
            db.add(clause)
        
        await db.commit()
        return {"message": "Upload and processing successful", "doc_id": doc.id}
    
    finally:
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)

@app.post("/search", response_model=list[ClauseOut])
async def search(query_data: SearchQuery, db: AsyncSession = Depends(get_db)):
    results = await rag_service.search_and_rerank(
        query_data.query, 
        db, 
        kb_type=query_data.kb_type # ä¼ é€’ç±»å‹ç­›é€‰
    )
    
    out = []
    for clause, score in results:
        out.append(ClauseOut(
            id=clause.id,
            kb_type=clause.kb_type,
            chapter_path=clause.chapter_path,
            content=clause.content,
            score=float(score)
        ))
    return out

@app.post("/chat")
async def chat(
    request: ChatRequest, 
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    # è®°å½•æŸ¥è¯¢å¼€å§‹æ—¶é—´
    query_start_time = time.time()
    username = current_user or "anonymous"
    
    # è·å–æ¨¡å‹åç§°
    model_name = request.model or settings.LLM_MODEL
    
    # 1. RAG: Retrieve relevant clauses (è·å–åˆå§‹ç»“æœå’Œé‡æ’ç»“æœ)
    initial_results, reranked_results = await rag_service.search_and_rerank(
        request.message, 
        db, 
        kb_type=request.kb_type, # ä¼ é€’ç±»å‹ç­›é€‰
        return_initial_results=True
    )
    
    # ä½¿ç”¨é‡æ’ç»“æœæ„å»ºä¸Šä¸‹æ–‡
    context = ""
    referenced_doc_ids = set()  # æ”¶é›†å¼•ç”¨çš„æ–‡æ¡£ ID
    results = []  # ç”¨äºåç»­å¤„ç†
    for i, reranked_item in enumerate(reranked_results):
        # ä»é‡æ’ç»“æœä¸­è·å–å®Œæ•´çš„ clause ä¿¡æ¯
        clause_id = reranked_item["clause_id"]
        stmt = select(Clause).where(Clause.id == clause_id)
        result = await db.execute(stmt)
        clause = result.scalar_one_or_none()
        if clause:
            context += f"ã€å‚è€ƒèµ„æ–™{i+1}ã€‘ç« èŠ‚è·¯å¾„ï¼š{clause.chapter_path}\nå†…å®¹ï¼š{clause.content}\n\n"
            referenced_doc_ids.add(clause.doc_id)
            results.append((clause, reranked_item["rerank_score"]))
    
    # æŸ¥è¯¢å¼•ç”¨çš„æ–‡æ¡£ä¿¡æ¯
    referenced_docs = []
    if referenced_doc_ids:
        stmt = select(Document).where(Document.id.in_(referenced_doc_ids))
        result = await db.execute(stmt)
        referenced_docs = result.scalars().all()
    
    # ç”Ÿæˆå¼•ç”¨æ–‡ä»¶é“¾æ¥
    reference_links = ""
    if referenced_docs:
        reference_links = "\n\n---\n**ğŸ“ å¼•ç”¨æ–‡ä»¶ï¼š**\n"
        for doc in referenced_docs:
            file_url = oss_service.get_file_url(doc.oss_key)
            reference_links += f"- [{doc.filename}]({file_url})\n"
    
    # 2. Prepare Prompt
    # ä»æ•°æ®åº“è·å–æç¤ºè¯æ¨¡æ¿ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
    default_system_template = """ä½ æ˜¯å¸‚æ”¿è®¾æ–½è¿ç»´ä¸“å®¶ï¼Œç²¾é€šç»“æ„å¥åº·ç›‘æµ‹ã€ç—…å®³è¯Šæ–­ã€å…»æŠ¤ä¿®å¤ã€åº”æ€¥å¤„ç½®åŠè¡Œä¸šè§„èŒƒã€‚è¯·åŸºäºå¸‚æ”¿è®¾æ–½å…¨ç”Ÿå‘½å‘¨æœŸè¿ç»´ç»éªŒï¼Œç”¨ä¸“ä¸šã€ç®€æ´çš„è¯­è¨€è§£ç­”é“æ¡¥éš§å·¡æ£€ã€ç»´ä¿®ã€ç®¡ç†ç›¸å…³é—®é¢˜ã€‚
    å°†æ ¹æ®æä¾›çš„ã€å‚è€ƒèµ„æ–™ã€‘æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ã€‚
    ä½ çš„å›ç­”åº”ä½“ç°å¸‚æ”¿è®¾æ–½è¿ç»´ä¸“å®¶çš„èº«ä»½ï¼šé€»è¾‘æ¸…æ™°ã€æœ¯è¯­è§„èŒƒã€å¼ºè°ƒå®‰å…¨ä¸åˆè§„ã€‚

    é‡è¦æç¤ºï¼šè¯·ä¸è¦åœ¨å›ç­”ä¸­åŒ…å«å¼•ç”¨æ–‡ä»¶ã€å‚è€ƒæ–‡çŒ®æˆ–é“¾æ¥ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å°†ç”±ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ ã€‚

    ã€å‚è€ƒèµ„æ–™ã€‘
    {context}
"""
    prompt_template = await get_prompt(db, "rag_system_prompt", default_system_template)
    system_prompt = prompt_template.format(context=context)
    
    messages = [{"role": "system", "content": system_prompt}]
    # Add history
    for msg in request.history:
        messages.append({"role": msg.role, "content": msg.content})
    # Add current message
    messages.append({"role": "user", "content": request.message})
    
    # 3. Call LLM
    if request.stream:
        async def stream_wrapper():
            collected_content = ""  # æ”¶é›†æ‰€æœ‰å†…å®¹
            try:
                print(f"[DEBUG] å¼€å§‹è°ƒç”¨ LLMï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}")
                # chat_completion æ˜¯ async å‡½æ•°ï¼Œè¿”å›å¼‚æ­¥ç”Ÿæˆå™¨å¯¹è±¡
                stream = await llm_service.chat_completion(messages, model=model_name, stream=True)
                print("[DEBUG] LLM æµå¼å“åº”å·²å»ºç«‹ï¼Œå¼€å§‹ä¼ è¾“æ•°æ®...")
                chunk_count = 0
                async for chunk in stream:
                    chunk_count += 1
                    if chunk_count <= 3:  # åªæ‰“å°å‰3ä¸ªchunkçš„è°ƒè¯•ä¿¡æ¯
                        print(f"[DEBUG] å‘é€æ•°æ®å— {chunk_count}: {chunk[:50]}...")
                    collected_content += chunk
                    yield chunk
                print(f"[DEBUG] æµå¼å“åº”å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
                # åœ¨æµå¼å“åº”ç»“æŸæ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å·²åŒ…å«å¼•ç”¨æ–‡ä»¶éƒ¨åˆ†ï¼Œé¿å…é‡å¤æ·»åŠ 
                if reference_links:
                    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«å¼•ç”¨æ–‡ä»¶ç›¸å…³çš„æ ‡è®°
                    has_reference_section = (
                        "å¼•ç”¨æ–‡ä»¶" in collected_content or 
                        "ğŸ“" in collected_content or
                        "å‚è€ƒæ–‡çŒ®" in collected_content.lower() or
                        "cited documents" in collected_content.lower()
                    )
                    if not has_reference_section:
                        yield reference_links
                        collected_content += reference_links
                    else:
                        print("[DEBUG] æ£€æµ‹åˆ°å›ç­”ä¸­å·²åŒ…å«å¼•ç”¨æ–‡ä»¶éƒ¨åˆ†ï¼Œè·³è¿‡æ·»åŠ ä»¥é¿å…é‡å¤")
            except Exception as e:
                # å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                import traceback
                error_detail = str(e)
                print(f"[ERROR] æµå¼å“åº”å‡ºé”™: {error_detail}")
                traceback.print_exc()
                error_msg = f"\n\nâŒ é”™è¯¯: {error_detail}\n\nè¯·æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®ã€‚"
                collected_content = error_msg
                yield error_msg
            finally:
                # ä¿å­˜æŸ¥è¯¢è®°å½•ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å“åº”ï¼‰
                try:
                    query_duration = time.time() - query_start_time
                    # JSONB å¯ä»¥ç›´æ¥å­˜å‚¨ Python å­—å…¸
                    chat_log = ChatQueryLog(
                        username=username,
                        query_content=request.message,
                        initial_rag_results=initial_results,  # JSONB ç›´æ¥å­˜å‚¨å­—å…¸
                        reranked_results=reranked_results,  # JSONB ç›´æ¥å­˜å‚¨å­—å…¸
                        llm_response=collected_content,
                        model_name=model_name,
                        query_duration_seconds=query_duration
                    )
                    db.add(chat_log)
                    await db.commit()
                except Exception as e:
                    print(f"[ERROR] ä¿å­˜æŸ¥è¯¢è®°å½•å¤±è´¥: {e}")
        return StreamingResponse(stream_wrapper(), media_type="text/plain; charset=utf-8")
    else:
        try:
            response_content = await llm_service.chat_completion(messages, model=model_name, stream=False)
            # åœ¨éæµå¼å“åº”ä¸­ï¼Œæ£€æŸ¥æ˜¯å¦å·²åŒ…å«å¼•ç”¨æ–‡ä»¶éƒ¨åˆ†ï¼Œé¿å…é‡å¤æ·»åŠ 
            if reference_links:
                # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«å¼•ç”¨æ–‡ä»¶ç›¸å…³çš„æ ‡è®°
                has_reference_section = (
                    "å¼•ç”¨æ–‡ä»¶" in response_content or 
                    "ğŸ“" in response_content or
                    "å‚è€ƒæ–‡çŒ®" in response_content.lower() or
                    "cited documents" in response_content.lower()
                )
                if not has_reference_section:
                    response_content += reference_links
                else:
                    print("[DEBUG] æ£€æµ‹åˆ°å›ç­”ä¸­å·²åŒ…å«å¼•ç”¨æ–‡ä»¶éƒ¨åˆ†ï¼Œè·³è¿‡æ·»åŠ ä»¥é¿å…é‡å¤")
            
            # ä¿å­˜æŸ¥è¯¢è®°å½•
            try:
                query_duration = time.time() - query_start_time
                # JSONB å¯ä»¥ç›´æ¥å­˜å‚¨ Python å­—å…¸
                chat_log = ChatQueryLog(
                    username=username,
                    query_content=request.message,
                    initial_rag_results=initial_results,  # JSONB ç›´æ¥å­˜å‚¨å­—å…¸
                    reranked_results=reranked_results,  # JSONB ç›´æ¥å­˜å‚¨å­—å…¸
                    llm_response=response_content,
                    model_name=model_name,
                    query_duration_seconds=query_duration
                )
                db.add(chat_log)
                await db.commit()
            except Exception as e:
                print(f"[ERROR] ä¿å­˜æŸ¥è¯¢è®°å½•å¤±è´¥: {e}")
            
            return {"content": response_content}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")

@app.get("/chat-logs", response_model=PaginatedChatLogs)
async def get_chat_logs(
    page: int = 1,
    page_size: int = 15,
    username: Optional[str] = None,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """
    è·å– Chat æŸ¥è¯¢æ—¥å¿—åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰
    :param page: é¡µç ï¼Œä»1å¼€å§‹
    :param page_size: æ¯é¡µå¤§å°ï¼Œé»˜è®¤15
    :param username: å¯é€‰ï¼ŒæŒ‰ç”¨æˆ·åç­›é€‰
    :param db: æ•°æ®åº“ä¼šè¯
    :param current_user: å½“å‰ç”¨æˆ·ï¼ˆéœ€è¦ç™»å½•ï¼‰
    """
    # æ„å»ºæŸ¥è¯¢
    query = select(ChatQueryLog)
    
    # å¦‚æœæŒ‡å®šäº†ç”¨æˆ·åï¼Œæ·»åŠ ç­›é€‰æ¡ä»¶
    if username:
        query = query.where(ChatQueryLog.username == username)
    
    # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    query = query.order_by(desc(ChatQueryLog.query_time))
    
    # è®¡ç®—æ€»æ•°
    count_query = select(func.count()).select_from(ChatQueryLog)
    if username:
        count_query = count_query.where(ChatQueryLog.username == username)
    
    total_result = await db.execute(count_query)
    total = total_result.scalar()
    
    # è®¡ç®—åˆ†é¡µ
    total_pages = (total + page_size - 1) // page_size  # å‘ä¸Šå–æ•´
    offset = (page - 1) * page_size
    
    # è·å–å½“å‰é¡µæ•°æ®
    query = query.offset(offset).limit(page_size)
    result = await db.execute(query)
    logs = result.scalars().all()
    
    # è½¬æ¢ä¸ºè¾“å‡ºæ ¼å¼
    items = []
    for log in logs:
        items.append(ChatQueryLogOut(
            id=log.id,
            query_time=log.query_time,
            username=log.username,
            query_content=log.query_content,
            initial_rag_results=log.initial_rag_results,
            reranked_results=log.reranked_results,
            llm_response=log.llm_response,
            model_name=log.model_name,
            query_duration_seconds=log.query_duration_seconds
        ))
    
    return PaginatedChatLogs(
        total=total,
        page=page,
        page_size=page_size,
        total_pages=total_pages,
        items=items
    )

# --- æç¤ºè¯ç®¡ç†æ¥å£ ---

@app.get("/prompts", response_model=List[PromptOut])
async def list_prompts(
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """è·å–æ‰€æœ‰æç¤ºè¯"""
    stmt = select(Prompt).order_by(Prompt.name)
    result = await db.execute(stmt)
    return result.scalars().all()

@app.post("/prompts", response_model=PromptOut)
async def create_prompt(
    prompt_data: PromptCreate,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """åˆ›å»ºæ–°æç¤ºè¯"""
    # æ£€æŸ¥é‡å
    stmt = select(Prompt).where(Prompt.name == prompt_data.name)
    result = await db.execute(stmt)
    if result.scalar_one_or_none():
        raise HTTPException(status_code=400, detail=f"Prompt with name '{prompt_data.name}' already exists")
    
    new_prompt = Prompt(
        name=prompt_data.name,
        template=prompt_data.template,
        description=prompt_data.description,
        is_active=prompt_data.is_active
    )
    db.add(new_prompt)
    await db.commit()
    await db.refresh(new_prompt)
    return new_prompt

@app.put("/prompts/{prompt_id}", response_model=PromptOut)
async def update_prompt(
    prompt_id: UUID,
    prompt_data: PromptUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """æ›´æ–°æç¤ºè¯"""
    stmt = select(Prompt).where(Prompt.id == prompt_id)
    result = await db.execute(stmt)
    prompt_obj = result.scalar_one_or_none()
    if not prompt_obj:
        raise HTTPException(status_code=404, detail="Prompt not found")
    
    # æ›´æ–°å­—æ®µ
    if prompt_data.name is not None:
        # å¦‚æœæ”¹åï¼Œæ£€æŸ¥æ˜¯å¦å†²çª
        if prompt_data.name != prompt_obj.name:
            name_check = await db.execute(select(Prompt).where(Prompt.name == prompt_data.name))
            if name_check.scalar_one_or_none():
                raise HTTPException(status_code=400, detail="New name already exists")
        prompt_obj.name = prompt_data.name
    
    if prompt_data.template is not None:
        prompt_obj.template = prompt_data.template
        prompt_obj.version += 1  # æ¯æ¬¡ä¿®æ”¹æ¨¡æ¿å¢åŠ ç‰ˆæœ¬å·
    
    if prompt_data.description is not None:
        prompt_obj.description = prompt_data.description
        
    if prompt_data.is_active is not None:
        prompt_obj.is_active = prompt_data.is_active
    
    prompt_obj.updated_at = datetime.utcnow()
    await db.commit()
    await db.refresh(prompt_obj)
    return prompt_obj

@app.delete("/prompts/{prompt_id}")
async def delete_prompt(
    prompt_id: UUID,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """åˆ é™¤æç¤ºè¯"""
    stmt = select(Prompt).where(Prompt.id == prompt_id)
    result = await db.execute(stmt)
    prompt_obj = result.scalar_one_or_none()
    if not prompt_obj:
        raise HTTPException(status_code=404, detail="Prompt not found")
    
    # ç¦æ­¢åˆ é™¤æ ¸å¿ƒç³»ç»Ÿæç¤ºè¯
    if prompt_obj.name == "rag_system_prompt":
        raise HTTPException(status_code=400, detail="Cannot delete core system prompt")
    
    await db.delete(prompt_obj)
    await db.commit()
    return {"message": "Prompt deleted successfully"}

# --- æ•°æ®å­—å…¸æ¥å£ ---

@app.get("/dicts/{type_name}", response_model=List[DictDataOut])
async def get_dict_by_type(type_name: str, db: AsyncSession = Depends(get_db)):
    """æ ¹æ®ç±»å‹åç§°è·å–å­—å…¸é¡¹ï¼ˆå¦‚ /dicts/kb_typeï¼‰"""
    stmt = (
        select(DictData)
        .join(DictType)
        .where(DictType.type_name == type_name, DictData.is_active == True)
        .order_by(DictData.sort_order)
    )
    result = await db.execute(stmt)
    return result.scalars().all()

@app.get("/dict-types", response_model=List[DictTypeOut])
async def list_dict_types(db: AsyncSession = Depends(get_db), current_user: str = Depends(get_current_user)):
    """åˆ—å‡ºæ‰€æœ‰å­—å…¸ç±»å‹ï¼ˆç®¡ç†ç«¯ä½¿ç”¨ï¼‰"""
    stmt = select(DictType)
    result = await db.execute(stmt)
    types = result.scalars().all()
    
    # æ‰‹åŠ¨åŠ è½½å…³è”æ•°æ®ï¼Œé¿å… N+1 æˆ–å»¶è¿ŸåŠ è½½é—®é¢˜
    out = []
    for t in types:
        data_stmt = select(DictData).where(DictData.type_id == t.id).order_by(DictData.sort_order)
        data_result = await db.execute(data_stmt)
        t_data = data_result.scalars().all()
        out.append(DictTypeOut(
            id=t.id,
            type_name=t.type_name,
            description=t.description,
            data=[DictDataOut.from_orm(d) for d in t_data]
        ))
    return out

@app.post("/dict-types", response_model=DictTypeOut)
async def create_dict_type(
    type_data: DictTypeCreate,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """åˆ›å»ºå­—å…¸ç±»å‹"""
    stmt = select(DictType).where(DictType.type_name == type_data.type_name)
    result = await db.execute(stmt)
    if result.scalar_one_or_none():
        raise HTTPException(status_code=400, detail="Dict type already exists")
    
    new_type = DictType(**type_data.dict())
    db.add(new_type)
    await db.commit()
    await db.refresh(new_type)
    return DictTypeOut(id=new_type.id, type_name=new_type.type_name, description=new_type.description, data=[])

@app.put("/dict-types/{type_id}", response_model=DictTypeOut)
async def update_dict_type(
    type_id: UUID,
    type_data: DictTypeUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """æ›´æ–°å­—å…¸ç±»å‹"""
    stmt = select(DictType).where(DictType.id == type_id)
    result = await db.execute(stmt)
    dict_type = result.scalar_one_or_none()
    if not dict_type:
        raise HTTPException(status_code=404, detail="Dict type not found")
    
    for key, value in type_data.dict(exclude_unset=True).items():
        setattr(dict_type, key, value)
    
    await db.commit()
    await db.refresh(dict_type)
    
    # åŠ è½½æ•°æ®é¡¹
    data_stmt = select(DictData).where(DictData.type_id == dict_type.id).order_by(DictData.sort_order)
    data_result = await db.execute(data_stmt)
    t_data = data_result.scalars().all()
    
    return DictTypeOut(
        id=dict_type.id,
        type_name=dict_type.type_name,
        description=dict_type.description,
        data=[DictDataOut.from_orm(d) for d in t_data]
    )

@app.delete("/dict-types/{type_id}")
async def delete_dict_type(
    type_id: UUID,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """åˆ é™¤å­—å…¸ç±»å‹"""
    stmt = select(DictType).where(DictType.id == type_id)
    result = await db.execute(stmt)
    dict_type = result.scalar_one_or_none()
    if not dict_type:
        raise HTTPException(status_code=404, detail="Dict type not found")
    
    # æ ¸å¿ƒå­—å…¸ç±»å‹ç¦æ­¢åˆ é™¤
    if dict_type.type_name == "kb_type":
        raise HTTPException(status_code=400, detail="Core dict type 'kb_type' cannot be deleted")
        
    await db.delete(dict_type)
    await db.commit()
    return {"message": "Dict type deleted"}

# --- å­—å…¸æ•°æ®é¡¹ CRUD ---

@app.post("/dict-data/{type_id}", response_model=DictDataOut)
async def create_dict_data(
    type_id: UUID,
    data_item: DictDataCreate,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """åˆ›å»ºå­—å…¸æ•°æ®é¡¹"""
    # æ£€æŸ¥ç±»å‹æ˜¯å¦å­˜åœ¨
    stmt = select(DictType).where(DictType.id == type_id)
    result = await db.execute(stmt)
    if not result.scalar_one_or_none():
        raise HTTPException(status_code=404, detail="Dict type not found")
        
    new_data = DictData(type_id=type_id, **data_item.dict())
    db.add(new_data)
    await db.commit()
    await db.refresh(new_data)
    return new_data

@app.put("/dict-data/{data_id}", response_model=DictDataOut)
async def update_dict_data(
    data_id: UUID,
    data_item: DictDataUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """æ›´æ–°å­—å…¸æ•°æ®é¡¹"""
    stmt = select(DictData).where(DictData.id == data_id)
    result = await db.execute(stmt)
    db_data = result.scalar_one_or_none()
    if not db_data:
        raise HTTPException(status_code=404, detail="Dict data not found")
    
    for key, value in data_item.dict(exclude_unset=True).items():
        setattr(db_data, key, value)
    
    await db.commit()
    await db.refresh(db_data)
    return db_data

@app.delete("/dict-data/{data_id}")
async def delete_dict_data(
    data_id: UUID,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """åˆ é™¤å­—å…¸æ•°æ®é¡¹"""
    stmt = select(DictData).where(DictData.id == data_id)
    result = await db.execute(stmt)
    db_data = result.scalar_one_or_none()
    if not db_data:
        raise HTTPException(status_code=404, detail="Dict data not found")
        
    await db.delete(db_data)
    await db.commit()
    return {"message": "Dict data deleted"}

# --- çŸ¥è¯†æ¡æ¬¾ç®¡ç†æ¥å£ ---

@app.get("/clauses", response_model=PaginatedClauses)
async def list_clauses(
    page: int = 1,
    page_size: int = 15,
    kb_type: Optional[str] = None,
    doc_id: Optional[UUID] = None,
    keyword: Optional[str] = None,
    is_verified: Optional[bool] = None,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """åˆ†é¡µè·å–çŸ¥è¯†æ¡æ¬¾åˆ—è¡¨"""
    stmt = select(Clause)
    if kb_type:
        stmt = stmt.where(Clause.kb_type == kb_type)
    if doc_id:
        stmt = stmt.where(Clause.doc_id == doc_id)
    if keyword:
        stmt = stmt.where(Clause.content.ilike(f"%{keyword}%") | Clause.chapter_path.ilike(f"%{keyword}%"))
    if is_verified is not None:
        stmt = stmt.where(Clause.is_verified == is_verified)
    
    # è®¡ç®—æ€»æ•°
    count_stmt = select(func.count()).select_from(stmt.subquery())
    total_res = await db.execute(count_stmt)
    total = total_res.scalar()
    
    # åˆ†é¡µæ’åºï¼š
    # 1. ä¼˜å…ˆæ˜¾ç¤ºæœªæ ¡éªŒ (is_verified ä¸º False çš„æ’åœ¨å‰é¢)
    # 2. å…¶æ¬¡æŒ‰ç« èŠ‚è·¯å¾„æ’åº
    # 3. æœ€åæŒ‰ ID æ’åºï¼ˆä¿åº•ï¼Œç¡®ä¿ç¼–è¾‘åç‰©ç†ä½ç½®å˜äº†ä½†é€»è¾‘æ’åºä¸å˜ï¼‰
    stmt = stmt.order_by(
        Clause.is_verified.asc(), 
        Clause.chapter_path.asc(), 
        Clause.id.asc()
    ).offset((page - 1) * page_size).limit(page_size)
    result = await db.execute(stmt)
    clauses = result.scalars().all()
    
    # è·å–æ–‡æ¡£åç§°æ˜ å°„
    doc_ids = list(set(c.doc_id for c in clauses if c.doc_id))
    doc_map = {}
    if doc_ids:
        doc_stmt = select(Document.id, Document.filename).where(Document.id.in_(doc_ids))
        doc_res = await db.execute(doc_stmt)
        doc_map = {row.id: row.filename for row in doc_res}
    
    return PaginatedClauses(
        total=total,
        page=page,
        page_size=page_size,
        total_pages=(total + page_size - 1) // page_size,
        items=[
            ClauseOut(
                id=c.id,
                kb_type=c.kb_type,
                chapter_path=c.chapter_path,
                content=c.content,
                is_verified=c.is_verified, # ç¡®ä¿è¿”å›çœŸå®çš„æ ¡éªŒçŠ¶æ€
                doc_id=c.doc_id, # è¿”å›æ–‡æ¡£ ID
                doc_name=doc_map.get(c.doc_id, "æ‰‹åŠ¨æ–°å¢") # è¿”å›æ–‡æ¡£åç§°
            ) for c in clauses
        ]
    )

@app.post("/clauses", response_model=ClauseOut)
async def create_clause(
    data: ClauseCreate,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """æ‰‹åŠ¨åˆ›å»ºçŸ¥è¯†æ¡æ¬¾"""
    embedding = rag_service.get_embedding(data.content)
    new_clause = Clause(
        kb_type=data.kb_type,
        chapter_path=data.chapter_path,
        content=data.content,
        doc_id=data.doc_id,
        embedding=embedding,
        is_verified=True # æ‰‹åŠ¨åˆ›å»ºçš„é»˜è®¤ä¸ºå·²æ ¡éªŒ
    )
    db.add(new_clause)
    await db.commit()
    await db.refresh(new_clause)
    
    # è·å–æ–‡æ¡£åç§°
    doc_name = "æ‰‹åŠ¨æ–°å¢"
    if new_clause.doc_id:
        doc_stmt = select(Document.filename).where(Document.id == new_clause.doc_id)
        doc_res = await db.execute(doc_stmt)
        doc_name = doc_res.scalar() or "æ‰‹åŠ¨æ–°å¢"

    return ClauseOut(
        id=new_clause.id,
        kb_type=new_clause.kb_type,
        chapter_path=new_clause.chapter_path,
        content=new_clause.content,
        is_verified=new_clause.is_verified,
        doc_id=new_clause.doc_id,
        doc_name=doc_name
    )

@app.put("/clauses/{clause_id}", response_model=ClauseOut)
async def update_clause(
    clause_id: UUID,
    data: ClauseUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """æ›´æ–°çŸ¥è¯†æ¡æ¬¾"""
    stmt = select(Clause).where(Clause.id == clause_id)
    result = await db.execute(stmt)
    clause = result.scalar_one_or_none()
    if not clause:
        raise HTTPException(status_code=404, detail="Clause not found")
    
    # å¦‚æœä¿®æ”¹äº†å†…å®¹ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆå‘é‡
    if data.content is not None and data.content != clause.content:
        clause.embedding = rag_service.get_embedding(data.content)
        clause.content = data.content
    
    if data.kb_type is not None:
        clause.kb_type = data.kb_type
    if data.chapter_path is not None:
        clause.chapter_path = data.chapter_path
    if data.is_verified is not None:
        clause.is_verified = data.is_verified
    if data.doc_id is not None:
        clause.doc_id = data.doc_id
        
    await db.commit()
    await db.refresh(clause)
    
    # è·å–æ–‡æ¡£åç§°
    doc_name = "æ‰‹åŠ¨æ–°å¢"
    if clause.doc_id:
        doc_stmt = select(Document.filename).where(Document.id == clause.doc_id)
        doc_res = await db.execute(doc_stmt)
        doc_name = doc_res.scalar() or "æ‰‹åŠ¨æ–°å¢"

    return ClauseOut(
        id=clause.id,
        kb_type=clause.kb_type,
        chapter_path=clause.chapter_path,
        content=clause.content,
        is_verified=clause.is_verified,
        doc_id=clause.doc_id,
        doc_name=doc_name
    )

@app.delete("/clauses/{clause_id}")
async def delete_clause(
    clause_id: UUID,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """åˆ é™¤çŸ¥è¯†æ¡æ¬¾"""
    stmt = select(Clause).where(Clause.id == clause_id)
    result = await db.execute(stmt)
    clause = result.scalar_one_or_none()
    if not clause:
        raise HTTPException(status_code=404, detail="Clause not found")
        
    await db.delete(clause)
    await db.commit()
    return {"message": "Clause deleted"}

# --- æ–‡æ¡£ç®¡ç†æ¥å£ ---

@app.get("/documents", response_model=List[DocumentOut])
async def list_documents(
    keyword: Optional[str] = None,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """è·å–æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…æ–‡ä»¶åï¼‰"""
    stmt = select(Document)
    if keyword:
        stmt = stmt.where(Document.filename.ilike(f"%{keyword}%"))
    stmt = stmt.order_by(Document.upload_time.desc())
    result = await db.execute(stmt)
    return result.scalars().all()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
