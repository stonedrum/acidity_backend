import os
# å¿…é¡»åœ¨å¯¼å…¥ä»»ä½• huggingface ç›¸å…³åº“ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['HF_DATASETS_OFFLINE'] = '1'

from fastapi import FastAPI, Depends, UploadFile, File, HTTPException, status
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc
from .database import get_db, init_db
from .models import User, Document, Clause, ApiCallLog, ChatQueryLog
from .schemas import UserCreate, UserLogin, Token, DocumentOut, SearchQuery, ClauseOut, ChatRequest, ChatQueryLogOut, PaginatedChatLogs, LogQueryParams
from .auth import get_password_hash, verify_password, create_access_token, get_current_user
from .services.oss_service import oss_service
from .services.pdf_service import pdf_service
from .services.rag_service import rag_service
from .services.llm_service import llm_service
from .config import settings
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
from starlette.responses import Response
import shutil
import uuid
import time
import json
from typing import Optional

app = FastAPI(title="Standard Knowledge Base RAG")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ¥å£è°ƒç”¨æ—¥å¿—ä¸­é—´ä»¶
class ApiLoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        
        # è·å–ç”¨æˆ·åï¼ˆä»tokenä¸­è§£æï¼Œå¦‚æœå­˜åœ¨ï¼‰
        username = None
        try:
            auth_header = request.headers.get("Authorization")
            if auth_header and auth_header.startswith("Bearer "):
                token = auth_header.split(" ")[1]
                from jose import jwt
                try:
                    payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
                    username = payload.get("sub")
                except:
                    pass
        except:
            pass
        
        # è·å–è¯·æ±‚å‚æ•°
        body = None
        try:
            if request.method in ["POST", "PUT", "PATCH"]:
                body_bytes = await request.body()
                if body_bytes:
                    try:
                        body = json.loads(body_bytes.decode())
                    except:
                        body = {"raw": body_bytes.decode()[:500]}  # é™åˆ¶é•¿åº¦
        except:
            pass
        
        # æ‰§è¡Œè¯·æ±‚
        response = await call_next(request)
        
        # è®¡ç®—å“åº”æ—¶é—´
        response_time_ms = (time.time() - start_time) * 1000
        
        # è®°å½•æ—¥å¿—ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å“åº”ï¼‰
        # æ³¨æ„ï¼šä¸­é—´ä»¶ä¸­ç›´æ¥è®¿é—®æ•°æ®åº“æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        # å®é™…è®°å½•åœ¨æ¥å£å±‚é¢å®Œæˆï¼Œä¸­é—´ä»¶ä¸»è¦ç”¨äºç»Ÿè®¡
        pass
        
        return response

app.add_middleware(ApiLoggingMiddleware)

@app.on_event("startup")
async def startup():
    await init_db()

@app.post("/register", response_model=Token)
async def register(user_data: UserCreate, db: AsyncSession = Depends(get_db)):
    db_user = await db.execute(select(User).where(User.username == user_data.username))
    if db_user.scalar_one_or_none():
        raise HTTPException(status_code=400, detail="Username already registered")
    
    hashed_password = get_password_hash(user_data.password)
    new_user = User(username=user_data.username, password_hash=hashed_password)
    db.add(new_user)
    await db.commit()
    
    access_token = create_access_token(data={"sub": new_user.username})
    return {"access_token": access_token, "token_type": "bearer"}

@app.post("/token", response_model=Token)
async def login(user_data: UserLogin, db: AsyncSession = Depends(get_db)):
    result = await db.execute(select(User).where(User.username == user_data.username))
    user = result.scalar_one_or_none()
    if not user or not verify_password(user_data.password, user.password_hash):
        raise HTTPException(status_code=401, detail="Incorrect username or password")
    
    access_token = create_access_token(data={"sub": user.username})
    return {"access_token": access_token, "token_type": "bearer"}

@app.post("/upload")
async def upload_pdf(file: UploadFile = File(...), db: AsyncSession = Depends(get_db), current_user: str = Depends(get_current_user)):
    # 1. Save locally temporarily
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)
    temp_file_path = os.path.join(temp_dir, f"{uuid.uuid4()}_{file.filename}")
    with open(temp_file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    try:
        # 2. Generate UUID-based filename (remove hyphens and keep file extension)
        # ç”ŸæˆåŸºäºUUIDçš„æ–‡ä»¶åï¼ˆå»æ‰æ¨ªçº¿ï¼Œä¿ç•™æ–‡ä»¶æ‰©å±•åï¼‰
        file_ext = os.path.splitext(file.filename)[1]  # è·å–æ–‡ä»¶æ‰©å±•åï¼Œå¦‚ .pdf
        uuid_name = str(uuid.uuid4()).replace('-', '')  # ç”ŸæˆUUIDå¹¶å»æ‰æ¨ªçº¿
        oss_filename = f"{uuid_name}{file_ext}"  # ç»„åˆï¼šuuidæ–‡ä»¶å + æ‰©å±•å
        
        # 3. Upload to OSS (ä¸Šä¼ åˆ° /laws/ ç›®å½•ï¼Œä½¿ç”¨UUIDæ–‡ä»¶å)
        with open(temp_file_path, "rb") as f:
            oss_key = oss_service.upload_file(f.read(), oss_filename, directory="laws")
        
        # 4. Check if filename already exists (filename must be unique)
        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨ï¼ˆæ–‡ä»¶åå¿…é¡»å”¯ä¸€ï¼‰
        existing_doc = await db.execute(select(Document).where(Document.filename == file.filename))
        if existing_doc.scalar_one_or_none():
            raise HTTPException(
                status_code=400, 
                detail=f"æ–‡ä»¶ '{file.filename}' å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å"
            )
        
        # 5. Create Document record (ä¿å­˜åŸå§‹æ–‡ä»¶åï¼ŒOSS keyä½¿ç”¨UUIDæ–‡ä»¶åï¼Œè®°å½•ä¸Šä¼ äºº)
        doc = Document(
            filename=file.filename, 
            oss_key=oss_key,
            uploader=current_user  # è®°å½•ä¸Šä¼ ç”¨æˆ·å
        )
        db.add(doc)
        await db.flush() # Get doc.id
        
        # 6. Parse PDF
        clauses_data = pdf_service.parse_pdf(temp_file_path)
        
        # 7. Embedding and Save Clauses
        for item in clauses_data:
            embedding = rag_service.get_embedding(item["content"])
            clause = Clause(
                doc_id=doc.id,
                chapter_path=item["chapter_path"],
                content=item["content"],
                embedding=embedding
            )
            db.add(clause)
        
        await db.commit()
        return {"message": "Upload and processing successful", "doc_id": doc.id}
    
    finally:
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)

@app.post("/search", response_model=list[ClauseOut])
async def search(query_data: SearchQuery, db: AsyncSession = Depends(get_db)):
    results = await rag_service.search_and_rerank(query_data.query, db)
    
    out = []
    for clause, score in results:
        out.append(ClauseOut(
            id=clause.id,
            chapter_path=clause.chapter_path,
            content=clause.content,
            score=float(score)
        ))
    return out

@app.post("/chat")
async def chat(
    request: ChatRequest, 
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    # è®°å½•æŸ¥è¯¢å¼€å§‹æ—¶é—´
    query_start_time = time.time()
    username = current_user or "anonymous"
    
    # è·å–æ¨¡å‹åç§°
    model_name = request.model or settings.LLM_MODEL
    
    # 1. RAG: Retrieve relevant clauses (è·å–åˆå§‹ç»“æœå’Œé‡æ’ç»“æœ)
    initial_results, reranked_results = await rag_service.search_and_rerank(
        request.message, db, return_initial_results=True
    )
    
    # ä½¿ç”¨é‡æ’ç»“æœæ„å»ºä¸Šä¸‹æ–‡
    context = ""
    referenced_doc_ids = set()  # æ”¶é›†å¼•ç”¨çš„æ–‡æ¡£ ID
    results = []  # ç”¨äºåç»­å¤„ç†
    for i, reranked_item in enumerate(reranked_results):
        # ä»é‡æ’ç»“æœä¸­è·å–å®Œæ•´çš„ clause ä¿¡æ¯
        clause_id = reranked_item["clause_id"]
        stmt = select(Clause).where(Clause.id == clause_id)
        result = await db.execute(stmt)
        clause = result.scalar_one_or_none()
        if clause:
            context += f"ã€å‚è€ƒèµ„æ–™{i+1}ã€‘ç« èŠ‚è·¯å¾„ï¼š{clause.chapter_path}\nå†…å®¹ï¼š{clause.content}\n\n"
            referenced_doc_ids.add(clause.doc_id)
            results.append((clause, reranked_item["rerank_score"]))
    
    # æŸ¥è¯¢å¼•ç”¨çš„æ–‡æ¡£ä¿¡æ¯
    referenced_docs = []
    if referenced_doc_ids:
        stmt = select(Document).where(Document.id.in_(referenced_doc_ids))
        result = await db.execute(stmt)
        referenced_docs = result.scalars().all()
    
    # ç”Ÿæˆå¼•ç”¨æ–‡ä»¶é“¾æ¥
    reference_links = ""
    if referenced_docs:
        reference_links = "\n\n---\n**ğŸ“ å¼•ç”¨æ–‡ä»¶ï¼š**\n"
        for doc in referenced_docs:
            file_url = oss_service.get_file_url(doc.oss_key)
            reference_links += f"- [{doc.filename}]({file_url})\n"
    
    # 2. Prepare Prompt
    system_prompt = f"""ä½ ä½ æ˜¯å¸‚æ”¿è®¾æ–½è¿ç»´ä¸“å®¶ï¼Œç²¾é€šç»“æ„å¥åº·ç›‘æµ‹ã€ç—…å®³è¯Šæ–­ã€å…»æŠ¤ä¿®å¤ã€åº”æ€¥å¤„ç½®åŠè¡Œä¸šè§„èŒƒã€‚è¯·åŸºäºå¸‚æ”¿è®¾æ–½å…¨ç”Ÿå‘½å‘¨æœŸè¿ç»´ç»éªŒï¼Œç”¨ä¸“ä¸šã€ç®€æ´çš„è¯­è¨€è§£ç­”é“æ¡¥éš§å·¡æ£€ã€ç»´ä¿®ã€ç®¡ç†ç›¸å…³é—®é¢˜ã€‚
    å°†æ ¹æ®æä¾›çš„ã€å‚è€ƒèµ„æ–™ã€‘æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ã€‚
    ä½ çš„å›ç­”åº”ä½“ç°å¸‚æ”¿è®¾æ–½è¿ç»´ä¸“å®¶çš„èº«ä»½ï¼šé€»è¾‘æ¸…æ™°ã€æœ¯è¯­è§„èŒƒã€å¼ºè°ƒå®‰å…¨ä¸åˆè§„ã€‚

    é‡è¦æç¤ºï¼šè¯·ä¸è¦åœ¨å›ç­”ä¸­åŒ…å«å¼•ç”¨æ–‡ä»¶ã€å‚è€ƒæ–‡çŒ®æˆ–é“¾æ¥ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å°†ç”±ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ ã€‚

    ã€å‚è€ƒèµ„æ–™ã€‘
    {context}
"""
    
    messages = [{"role": "system", "content": system_prompt}]
    # Add history
    for msg in request.history:
        messages.append({"role": msg.role, "content": msg.content})
    # Add current message
    messages.append({"role": "user", "content": request.message})
    
    # 3. Call LLM
    if request.stream:
        async def stream_wrapper():
            collected_content = ""  # æ”¶é›†æ‰€æœ‰å†…å®¹
            try:
                print(f"[DEBUG] å¼€å§‹è°ƒç”¨ LLMï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}")
                # chat_completion æ˜¯ async å‡½æ•°ï¼Œè¿”å›å¼‚æ­¥ç”Ÿæˆå™¨å¯¹è±¡
                stream = await llm_service.chat_completion(messages, model=model_name, stream=True)
                print("[DEBUG] LLM æµå¼å“åº”å·²å»ºç«‹ï¼Œå¼€å§‹ä¼ è¾“æ•°æ®...")
                chunk_count = 0
                async for chunk in stream:
                    chunk_count += 1
                    if chunk_count <= 3:  # åªæ‰“å°å‰3ä¸ªchunkçš„è°ƒè¯•ä¿¡æ¯
                        print(f"[DEBUG] å‘é€æ•°æ®å— {chunk_count}: {chunk[:50]}...")
                    collected_content += chunk
                    yield chunk
                print(f"[DEBUG] æµå¼å“åº”å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
                # åœ¨æµå¼å“åº”ç»“æŸæ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å·²åŒ…å«å¼•ç”¨æ–‡ä»¶éƒ¨åˆ†ï¼Œé¿å…é‡å¤æ·»åŠ 
                if reference_links:
                    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«å¼•ç”¨æ–‡ä»¶ç›¸å…³çš„æ ‡è®°
                    has_reference_section = (
                        "å¼•ç”¨æ–‡ä»¶" in collected_content or 
                        "ğŸ“" in collected_content or
                        "å‚è€ƒæ–‡çŒ®" in collected_content.lower() or
                        "cited documents" in collected_content.lower()
                    )
                    if not has_reference_section:
                        yield reference_links
                        collected_content += reference_links
                    else:
                        print("[DEBUG] æ£€æµ‹åˆ°å›ç­”ä¸­å·²åŒ…å«å¼•ç”¨æ–‡ä»¶éƒ¨åˆ†ï¼Œè·³è¿‡æ·»åŠ ä»¥é¿å…é‡å¤")
            except Exception as e:
                # å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                import traceback
                error_detail = str(e)
                print(f"[ERROR] æµå¼å“åº”å‡ºé”™: {error_detail}")
                traceback.print_exc()
                error_msg = f"\n\nâŒ é”™è¯¯: {error_detail}\n\nè¯·æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®ã€‚"
                collected_content = error_msg
                yield error_msg
            finally:
                # ä¿å­˜æŸ¥è¯¢è®°å½•ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡å“åº”ï¼‰
                try:
                    query_duration = time.time() - query_start_time
                    # JSONB å¯ä»¥ç›´æ¥å­˜å‚¨ Python å­—å…¸
                    chat_log = ChatQueryLog(
                        username=username,
                        query_content=request.message,
                        initial_rag_results=initial_results,  # JSONB ç›´æ¥å­˜å‚¨å­—å…¸
                        reranked_results=reranked_results,  # JSONB ç›´æ¥å­˜å‚¨å­—å…¸
                        llm_response=collected_content,
                        model_name=model_name,
                        query_duration_seconds=query_duration
                    )
                    db.add(chat_log)
                    await db.commit()
                except Exception as e:
                    print(f"[ERROR] ä¿å­˜æŸ¥è¯¢è®°å½•å¤±è´¥: {e}")
        return StreamingResponse(stream_wrapper(), media_type="text/plain; charset=utf-8")
    else:
        try:
            response_content = await llm_service.chat_completion(messages, model=model_name, stream=False)
            # åœ¨éæµå¼å“åº”ä¸­ï¼Œæ£€æŸ¥æ˜¯å¦å·²åŒ…å«å¼•ç”¨æ–‡ä»¶éƒ¨åˆ†ï¼Œé¿å…é‡å¤æ·»åŠ 
            if reference_links:
                # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«å¼•ç”¨æ–‡ä»¶ç›¸å…³çš„æ ‡è®°
                has_reference_section = (
                    "å¼•ç”¨æ–‡ä»¶" in response_content or 
                    "ğŸ“" in response_content or
                    "å‚è€ƒæ–‡çŒ®" in response_content.lower() or
                    "cited documents" in response_content.lower()
                )
                if not has_reference_section:
                    response_content += reference_links
                else:
                    print("[DEBUG] æ£€æµ‹åˆ°å›ç­”ä¸­å·²åŒ…å«å¼•ç”¨æ–‡ä»¶éƒ¨åˆ†ï¼Œè·³è¿‡æ·»åŠ ä»¥é¿å…é‡å¤")
            
            # ä¿å­˜æŸ¥è¯¢è®°å½•
            try:
                query_duration = time.time() - query_start_time
                # JSONB å¯ä»¥ç›´æ¥å­˜å‚¨ Python å­—å…¸
                chat_log = ChatQueryLog(
                    username=username,
                    query_content=request.message,
                    initial_rag_results=initial_results,  # JSONB ç›´æ¥å­˜å‚¨å­—å…¸
                    reranked_results=reranked_results,  # JSONB ç›´æ¥å­˜å‚¨å­—å…¸
                    llm_response=response_content,
                    model_name=model_name,
                    query_duration_seconds=query_duration
                )
                db.add(chat_log)
                await db.commit()
            except Exception as e:
                print(f"[ERROR] ä¿å­˜æŸ¥è¯¢è®°å½•å¤±è´¥: {e}")
            
            return {"content": response_content}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")

@app.get("/chat-logs", response_model=PaginatedChatLogs)
async def get_chat_logs(
    page: int = 1,
    page_size: int = 15,
    username: Optional[str] = None,
    db: AsyncSession = Depends(get_db),
    current_user: str = Depends(get_current_user)
):
    """
    è·å– Chat æŸ¥è¯¢æ—¥å¿—åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰
    :param page: é¡µç ï¼Œä»1å¼€å§‹
    :param page_size: æ¯é¡µå¤§å°ï¼Œé»˜è®¤15
    :param username: å¯é€‰ï¼ŒæŒ‰ç”¨æˆ·åç­›é€‰
    :param db: æ•°æ®åº“ä¼šè¯
    :param current_user: å½“å‰ç”¨æˆ·ï¼ˆéœ€è¦ç™»å½•ï¼‰
    """
    # æ„å»ºæŸ¥è¯¢
    query = select(ChatQueryLog)
    
    # å¦‚æœæŒ‡å®šäº†ç”¨æˆ·åï¼Œæ·»åŠ ç­›é€‰æ¡ä»¶
    if username:
        query = query.where(ChatQueryLog.username == username)
    
    # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    query = query.order_by(desc(ChatQueryLog.query_time))
    
    # è®¡ç®—æ€»æ•°
    count_query = select(func.count()).select_from(ChatQueryLog)
    if username:
        count_query = count_query.where(ChatQueryLog.username == username)
    
    total_result = await db.execute(count_query)
    total = total_result.scalar()
    
    # è®¡ç®—åˆ†é¡µ
    total_pages = (total + page_size - 1) // page_size  # å‘ä¸Šå–æ•´
    offset = (page - 1) * page_size
    
    # è·å–å½“å‰é¡µæ•°æ®
    query = query.offset(offset).limit(page_size)
    result = await db.execute(query)
    logs = result.scalars().all()
    
    # è½¬æ¢ä¸ºè¾“å‡ºæ ¼å¼
    items = []
    for log in logs:
        items.append(ChatQueryLogOut(
            id=log.id,
            query_time=log.query_time,
            username=log.username,
            query_content=log.query_content,
            initial_rag_results=log.initial_rag_results,
            reranked_results=log.reranked_results,
            llm_response=log.llm_response,
            model_name=log.model_name,
            query_duration_seconds=log.query_duration_seconds
        ))
    
    return PaginatedChatLogs(
        total=total,
        page=page,
        page_size=page_size,
        total_pages=total_pages,
        items=items
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
